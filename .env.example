# =============================================================================
# ZommaLabsKG Environment Variables
# =============================================================================
# Copy this file to .env and fill in your values
# cp .env.example .env

# -----------------------------------------------------------------------------
# Required: LLM APIs
# -----------------------------------------------------------------------------

# OpenAI - Required for embeddings (text-embedding-3-large)
OPENAI_API_KEY=sk-your-openai-key

# Google - Required for Gemini models (extraction, topic resolution)
GOOGLE_API_KEY=your-google-api-key

# -----------------------------------------------------------------------------
# Required: Neo4j Database
# -----------------------------------------------------------------------------

# Neo4j connection (local or Aura)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
NEO4J_DATABASE=neo4j

# -----------------------------------------------------------------------------
# Optional: Additional LLM Providers
# -----------------------------------------------------------------------------

# Anthropic - Optional, for alternative models
# ANTHROPIC_API_KEY=sk-ant-your-key

# Voyage - Optional, legacy embeddings (now using OpenAI)
# VOYAGE_API_KEY=pa-your-voyage-key

# xAI - Optional
# XAI_API_KEY=xai-your-key

# -----------------------------------------------------------------------------
# Optional: Observability
# -----------------------------------------------------------------------------

# LangSmith - Optional, for tracing/debugging
# LANGSMITH_API_KEY=your-langsmith-key
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_PROJECT=zommalabs-kg

# -----------------------------------------------------------------------------
# Optional: Pipeline Configuration
# -----------------------------------------------------------------------------

# Enable verbose logging
# VERBOSE=true

# Max concurrent LLM extractions (default: 5)
# EXTRACTION_CONCURRENCY=5
