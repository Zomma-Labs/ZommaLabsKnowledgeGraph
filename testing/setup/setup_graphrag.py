#!/usr/bin/env python3
"""
Setup script for building GraphRAG index on Beige Book data.

This script converts JSONL chunks from the ZommaLabsKG pipeline into a format
compatible with Microsoft's GraphRAG, then runs the indexing pipeline to create
entity extraction, community detection, and summarization.

Usage:
    uv run testing/setup/setup_graphrag.py
    uv run testing/setup/setup_graphrag.py --chunk-file src/chunker/SAVED/BeigeBook_20251015.jsonl
    uv run testing/setup/setup_graphrag.py --output-dir ./graphrag_custom
    uv run testing/setup/setup_graphrag.py --fast  # Use NLP-based extraction (cheaper)

Requirements:
    pip install graphrag

The created index can be used with GraphRAGSystem for querying.
"""

import argparse
import json
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path

from dotenv import load_dotenv

load_dotenv()

# Default paths
DEFAULT_CHUNK_FILE = "src/chunker/SAVED/BeigeBook_20251015.jsonl"
DEFAULT_OUTPUT_DIR = "./graphrag_beige"


def get_settings_yaml(fast_mode: bool = False) -> str:
    """Generate GraphRAG settings.yaml configuration.

    Args:
        fast_mode: If True, use NLP-based extraction (cheaper, faster).
                   If False, use full LLM extraction (more accurate).

    Returns:
        YAML configuration string.
    """
    # Use different models based on mode
    if fast_mode:
        extraction_model = "gpt-4o-mini"
        max_gleanings = 0
    else:
        extraction_model = "gpt-4.1"  # Use gpt-4.1 for extraction
        max_gleanings = 1

    return f"""# GraphRAG Configuration for Beige Book Data
# Generated by setup_graphrag.py on {datetime.now().isoformat()}

models:
  default_chat_model:
    type: openai_chat
    api_key: ${{OPENAI_API_KEY}}
    model: {extraction_model}
    max_tokens: 4096
    temperature: 0.0
    max_retries: 3
    tokens_per_minute: 80000
    requests_per_minute: 100

  default_embedding_model:
    type: openai_embedding
    api_key: ${{OPENAI_API_KEY}}
    model: text-embedding-3-large
    max_retries: 3
    tokens_per_minute: 500000
    requests_per_minute: 500

input:
  type: file
  file_type: text
  file_pattern: ".*\\\\.txt$$"
  base_dir: input
  encoding: utf-8

chunks:
  size: 1200
  overlap: 100
  strategy: tokens

output:
  type: file
  base_dir: output

cache:
  type: file
  base_dir: cache

reporting:
  type: file
  base_dir: reports

extract_graph:
  entity_types:
    - organization
    - person
    - location
    - event
    - economic_indicator
    - industry
    - policy
    - financial_metric
  max_gleanings: {max_gleanings}

summarize_descriptions:
  max_length: 500

cluster_graph:
  max_cluster_size: 10
  use_lcc: true

community_reports:
  max_length: 2000
  max_input_length: 8000

embed_text:
  enabled: true

embed_graph:
  enabled: true

umap:
  enabled: false

snapshots:
  graphml: true
  embeddings: false
  transient: false
"""


def prepare_input_data(chunk_file: str, output_dir: str, verbose: bool = False) -> int:
    """Convert JSONL chunks to GraphRAG input format.

    GraphRAG expects text files in an input/ directory. We convert each chunk
    or group of chunks into text files that preserve the document structure.

    Args:
        chunk_file: Path to the JSONL file containing chunks.
        output_dir: Path to the GraphRAG project directory.
        verbose: Print detailed progress.

    Returns:
        Number of chunks processed.
    """
    chunk_path = Path(chunk_file)
    output_path = Path(output_dir)
    input_dir = output_path / "input"

    if not chunk_path.exists():
        raise FileNotFoundError(f"Chunk file not found: {chunk_path}")

    # Create input directory
    input_dir.mkdir(parents=True, exist_ok=True)

    # Read all chunks
    chunks = []
    with open(chunk_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                chunks.append(json.loads(line))

    if not chunks:
        raise ValueError(f"No chunks found in {chunk_file}")

    print(f"[setup_graphrag] Loaded {len(chunks)} chunks from {chunk_file}")

    # Group chunks by document
    doc_chunks: dict[str, list] = {}
    for chunk in chunks:
        doc_id = chunk.get("doc_id", "unknown")
        if doc_id not in doc_chunks:
            doc_chunks[doc_id] = []
        doc_chunks[doc_id].append(chunk)

    print(f"[setup_graphrag] Found {len(doc_chunks)} document(s)")

    # Write each document as a text file
    total_written = 0
    for doc_id, doc_chunk_list in doc_chunks.items():
        # Sort chunks by chunk_id to maintain order
        doc_chunk_list.sort(key=lambda c: c.get("chunk_id", ""))

        # Build document text with headers
        doc_lines = []
        doc_lines.append(f"# Document: {doc_id}")

        # Add metadata if available
        if doc_chunk_list and "metadata" in doc_chunk_list[0]:
            metadata = doc_chunk_list[0]["metadata"]
            if "document_date" in metadata:
                doc_lines.append(f"Date: {metadata['document_date']}")

        doc_lines.append("")  # Blank line

        # Add each chunk with its header path for context
        current_header = None
        for chunk in doc_chunk_list:
            header_path = chunk.get("header_path", "")

            # Add section header if it changed
            if header_path and header_path != current_header:
                doc_lines.append(f"\n## {header_path}\n")
                current_header = header_path

            # Add chunk body
            body = chunk.get("body", "").strip()
            if body:
                doc_lines.append(body)
                doc_lines.append("")  # Blank line between chunks

        # Write to file
        output_file = input_dir / f"{doc_id}.txt"
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(doc_lines))

        if verbose:
            print(f"  -> Wrote {len(doc_chunk_list)} chunks to {output_file.name}")

        total_written += len(doc_chunk_list)

    print(f"[setup_graphrag] Prepared {total_written} chunks across {len(doc_chunks)} file(s) in {input_dir}")
    return total_written


def create_settings(output_dir: str, fast_mode: bool = False) -> Path:
    """Create GraphRAG settings.yaml configuration.

    Args:
        output_dir: Path to the GraphRAG project directory.
        fast_mode: Use faster/cheaper NLP-based extraction.

    Returns:
        Path to the created settings file.
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    settings_file = output_path / "settings.yaml"
    settings_content = get_settings_yaml(fast_mode=fast_mode)

    with open(settings_file, "w", encoding="utf-8") as f:
        f.write(settings_content)

    print(f"[setup_graphrag] Created settings.yaml at {settings_file}")
    return settings_file


def create_env_file(output_dir: str) -> Path:
    """Create .env file with API key reference.

    Args:
        output_dir: Path to the GraphRAG project directory.

    Returns:
        Path to the created .env file.
    """
    output_path = Path(output_dir)
    env_file = output_path / ".env"

    # Get API key from environment
    api_key = os.environ.get("OPENAI_API_KEY", "")

    if not api_key:
        print("[setup_graphrag] WARNING: OPENAI_API_KEY not found in environment!")
        print("  Please set it before running the index.")

    with open(env_file, "w", encoding="utf-8") as f:
        f.write(f"GRAPHRAG_API_KEY={api_key}\n")

    print(f"[setup_graphrag] Created .env file at {env_file}")
    return env_file


def run_graphrag_init(output_dir: str) -> bool:
    """Run graphrag init to set up directory structure.

    Args:
        output_dir: Path to the GraphRAG project directory.

    Returns:
        True if successful, False otherwise.
    """
    print(f"[setup_graphrag] Running graphrag init in {output_dir}...")

    try:
        result = subprocess.run(
            ["graphrag", "init", "--root", output_dir],
            capture_output=True,
            text=True,
            timeout=60,
        )

        if result.returncode != 0:
            print(f"[setup_graphrag] graphrag init failed: {result.stderr}")
            return False

        print(f"[setup_graphrag] graphrag init completed successfully")
        return True

    except FileNotFoundError:
        print("[setup_graphrag] ERROR: graphrag CLI not found!")
        print("  Install with: pip install graphrag")
        return False
    except subprocess.TimeoutExpired:
        print("[setup_graphrag] ERROR: graphrag init timed out")
        return False


def run_graphrag_index(output_dir: str, verbose: bool = False) -> bool:
    """Run GraphRAG indexing process.

    This is the main indexing step that:
    - Extracts entities and relationships from text
    - Builds community detection and hierarchical summaries
    - Creates embeddings for vector search

    Args:
        output_dir: Path to the GraphRAG project directory.
        verbose: Print detailed progress.

    Returns:
        True if successful, False otherwise.
    """
    print(f"[setup_graphrag] Starting GraphRAG indexing...")
    print(f"  This may take 10-30 minutes depending on data size.")
    print(f"  Progress will be shown below:\n")

    try:
        # Run graphrag index with streaming output
        cmd = ["graphrag", "index", "--root", output_dir]
        if verbose:
            cmd.append("--verbose")

        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True,
        )

        # Stream output in real-time
        for line in process.stdout:
            print(f"  {line}", end="")

        process.wait()

        if process.returncode != 0:
            print(f"\n[setup_graphrag] ERROR: graphrag index failed with code {process.returncode}")
            return False

        print(f"\n[setup_graphrag] Indexing completed successfully!")
        return True

    except FileNotFoundError:
        print("[setup_graphrag] ERROR: graphrag CLI not found!")
        print("  Install with: pip install graphrag")
        return False
    except Exception as e:
        print(f"[setup_graphrag] ERROR: {e}")
        return False


def save_manifest(output_dir: str, chunk_file: str, chunk_count: int, fast_mode: bool) -> Path:
    """Save manifest.json with metadata about the index.

    Args:
        output_dir: Path to the GraphRAG project directory.
        chunk_file: Source chunk file path.
        chunk_count: Number of chunks processed.
        fast_mode: Whether fast mode was used.

    Returns:
        Path to the created manifest file.
    """
    output_path = Path(output_dir)
    manifest_file = output_path / "manifest.json"

    manifest = {
        "created_at": datetime.now().isoformat(),
        "source_file": str(Path(chunk_file).absolute()),
        "chunk_count": chunk_count,
        "indexing_mode": "fast" if fast_mode else "standard",
        "graphrag_version": "0.3+",  # Current expected version
        "index_path": str(output_path / "output"),
        "notes": "Generated by testing/setup/setup_graphrag.py for GraphRAGSystem evaluation",
    }

    with open(manifest_file, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2)

    print(f"[setup_graphrag] Saved manifest to {manifest_file}")
    return manifest_file


def verify_index(output_dir: str) -> bool:
    """Verify the GraphRAG index was created correctly.

    Args:
        output_dir: Path to the GraphRAG project directory.

    Returns:
        True if index is valid, False otherwise.
    """
    output_path = Path(output_dir)

    # Check for required parquet files (support both old and new naming)
    required_files = [
        ("entities.parquet", "create_final_entities.parquet"),
        ("community_reports.parquet", "create_final_community_reports.parquet"),
    ]

    # GraphRAG 0.3+ puts files in output/ subdirectory
    index_dir = output_path / "output"
    if not index_dir.exists():
        index_dir = output_path

    missing_files = []
    found_files = {}
    for new_name, old_name in required_files:
        if (index_dir / new_name).exists():
            found_files[new_name] = index_dir / new_name
        elif (index_dir / old_name).exists():
            found_files[new_name] = index_dir / old_name
        else:
            missing_files.append(new_name)

    if missing_files:
        print(f"[setup_graphrag] WARNING: Index incomplete. Missing: {missing_files}")
        return False

    # Count entities and reports
    try:
        import pandas as pd

        entities_df = pd.read_parquet(found_files["entities.parquet"])
        reports_df = pd.read_parquet(found_files["community_reports.parquet"])

        print(f"[setup_graphrag] Index verified:")
        print(f"  - Entities: {len(entities_df)}")
        print(f"  - Community reports: {len(reports_df)}")

        # Check for optional files (support both naming conventions)
        optional_files = [
            (["text_units.parquet", "create_final_text_units.parquet"], "Text units"),
            (["relationships.parquet", "create_final_relationships.parquet"], "Relationships"),
        ]

        for filenames, label in optional_files:
            for filename in filenames:
                if (index_dir / filename).exists():
                    df = pd.read_parquet(index_dir / filename)
                    print(f"  - {label}: {len(df)}")
                    break

        return True

    except ImportError:
        print("[setup_graphrag] pandas not available for verification")
        return True  # Assume OK if we can't verify
    except Exception as e:
        print(f"[setup_graphrag] Error verifying index: {e}")
        return False


def main():
    """Main entry point for the setup script."""
    parser = argparse.ArgumentParser(
        description="Setup GraphRAG index for Beige Book data",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Basic usage with defaults
    uv run testing/setup/setup_graphrag.py

    # Use a different chunk file
    uv run testing/setup/setup_graphrag.py --chunk-file src/chunker/SAVED/BeigeBook_20251126.jsonl

    # Use fast mode (cheaper, uses NLP instead of full LLM)
    uv run testing/setup/setup_graphrag.py --fast

    # Prepare data only (don't run indexing)
    uv run testing/setup/setup_graphrag.py --prepare-only

After completion, use with GraphRAGSystem:
    from testing.systems.graphrag_system import GraphRAGSystem
    system = GraphRAGSystem(index_path="./graphrag_beige/output")
    answer, evidence = await system.query("What economic conditions were reported?")
""",
    )

    parser.add_argument(
        "--chunk-file",
        default=DEFAULT_CHUNK_FILE,
        help=f"Path to JSONL chunk file (default: {DEFAULT_CHUNK_FILE})",
    )

    parser.add_argument(
        "--output-dir",
        default=DEFAULT_OUTPUT_DIR,
        help=f"Output directory for GraphRAG index (default: {DEFAULT_OUTPUT_DIR})",
    )

    parser.add_argument(
        "--fast",
        action="store_true",
        help="Use fast mode (NLP-based extraction, cheaper but less accurate)",
    )

    parser.add_argument(
        "--prepare-only",
        action="store_true",
        help="Only prepare input data and config, don't run indexing",
    )

    parser.add_argument(
        "--skip-init",
        action="store_true",
        help="Skip graphrag init (use if you already have a project)",
    )

    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose output",
    )

    args = parser.parse_args()

    print("=" * 60)
    print("GraphRAG Index Setup")
    print("=" * 60)
    print(f"  Chunk file: {args.chunk_file}")
    print(f"  Output dir: {args.output_dir}")
    print(f"  Mode: {'fast (NLP-based)' if args.fast else 'standard (LLM-based)'}")
    print("=" * 60)
    print()

    # Check for OPENAI_API_KEY
    if not os.environ.get("OPENAI_API_KEY"):
        print("ERROR: OPENAI_API_KEY environment variable not set!")
        print("  Please set it before running this script.")
        sys.exit(1)

    try:
        # Step 1: Prepare input data
        print("[Step 1/5] Preparing input data...")
        chunk_count = prepare_input_data(
            args.chunk_file,
            args.output_dir,
            verbose=args.verbose
        )

        # Step 2: Create settings.yaml
        print("\n[Step 2/5] Creating settings.yaml...")
        create_settings(args.output_dir, fast_mode=args.fast)

        # Step 3: Create .env file
        print("\n[Step 3/5] Creating .env file...")
        create_env_file(args.output_dir)

        if args.prepare_only:
            print("\n[setup_graphrag] Preparation complete (--prepare-only mode)")
            print(f"  To run indexing manually: graphrag index --root {args.output_dir}")
            save_manifest(args.output_dir, args.chunk_file, chunk_count, args.fast)
            sys.exit(0)

        # Step 4: Run graphrag indexing
        print("\n[Step 4/5] Running GraphRAG indexing...")
        success = run_graphrag_index(args.output_dir, verbose=args.verbose)

        if not success:
            print("\n[setup_graphrag] Indexing failed!")
            print("  Check the error messages above for details.")
            print("  You can try running manually: graphrag index --root {args.output_dir}")
            sys.exit(1)

        # Step 5: Verify and save manifest
        print("\n[Step 5/5] Verifying index and saving manifest...")
        verify_index(args.output_dir)
        save_manifest(args.output_dir, args.chunk_file, chunk_count, args.fast)

        print("\n" + "=" * 60)
        print("SUCCESS! GraphRAG index created.")
        print("=" * 60)
        print(f"\nTo use with GraphRAGSystem:")
        print(f'  from testing.systems.graphrag_system import GraphRAGSystem')
        print(f'  system = GraphRAGSystem(index_path="{args.output_dir}/output")')
        print(f'  answer, evidence = await system.query("Your question here")')
        print()

    except FileNotFoundError as e:
        print(f"\nERROR: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nERROR: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
