# GraphRAG Configuration for Beige Book Data
# Generated by setup_graphrag.py on 2026-01-22T12:07:07.141064

models:
  default_chat_model:
    type: openai_chat
    api_key: ${OPENAI_API_KEY}
    model: gpt-4.1
    max_tokens: 4096
    temperature: 0.0
    max_retries: 3
    tokens_per_minute: 80000
    requests_per_minute: 100

  default_embedding_model:
    type: openai_embedding
    api_key: ${OPENAI_API_KEY}
    model: text-embedding-3-large
    max_retries: 3
    tokens_per_minute: 500000
    requests_per_minute: 500

input:
  type: file
  file_type: text
  file_pattern: ".*\\.txt$$"
  base_dir: input
  encoding: utf-8

chunks:
  size: 1200
  overlap: 100
  strategy: tokens

output:
  type: file
  base_dir: output

cache:
  type: file
  base_dir: cache

reporting:
  type: file
  base_dir: reports

extract_graph:
  entity_types:
    - organization
    - person
    - location
    - event
    - economic_indicator
    - industry
    - policy
    - financial_metric
  max_gleanings: 1

summarize_descriptions:
  max_length: 500

cluster_graph:
  max_cluster_size: 10
  use_lcc: true

community_reports:
  max_length: 2000
  max_input_length: 8000

embed_text:
  enabled: true

embed_graph:
  enabled: true

umap:
  enabled: false

snapshots:
  graphml: true
  embeddings: false
  transient: false
